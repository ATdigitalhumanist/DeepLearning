{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1HSN5Rlfgkw8br4hW32rwbD5Wp7vfWrNj",
      "authorship_tag": "ABX9TyNBK8Pdd3LgmM09XYXE5js/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ATdigitalhumanist/DeepLearning/blob/main/DL_Assignment_Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Image Classification using Transfer Learning\n",
        "**Objective**: The objective of this assignment is to develop an image classification model using transfer learning. You will find a pretrain a neural network model, and then use transfer learning to classify logos of popular food chains."
      ],
      "metadata": {
        "id": "ElnEaDOUejl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnylFz1XX2j2"
      },
      "outputs": [],
      "source": [
        "# for System library\n",
        "import os\n",
        "import random\n",
        "from io import BytesIO\n",
        "\n",
        "# for numerical processing library\n",
        "import numpy as np\n",
        "\n",
        "# for tensorflow and keras processing librarcy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16  # You can change this to ResNet or another model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# for spliting dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for image loading and proecssing\n",
        "import cv2\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "8-Gm6RnxYClo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in the Colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "hgoQuB3LjKzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Training Data from Logos3 folder"
      ],
      "metadata": {
        "id": "zO9XyMXi3ZA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseDir = \"/content/gdrive/MyDrive/DL Assignment/Part 3/logos3/train\"\n",
        "testDir = \"/content/gdrive/MyDrive/DL Assignment/Part 3/logos3/test\"\n",
        "\n",
        "Name=[]\n",
        "\n",
        "for file in os.listdir(baseDir):\n",
        "  Name+=[file]\n",
        "\n",
        "print(Name)\n",
        "print(len(Name))\n",
        "\n",
        "brandMap = dict(zip(Name, [t for t in range(len(Name))]))\n",
        "print(brandMap)\n",
        "rBrandMap=dict(zip([t for t in range(len(Name))],Name))\n",
        "\n",
        "testName=[]\n",
        "\n",
        "for file in os.listdir(testDir):\n",
        "  testName+=[file]\n",
        "\n",
        "print(testName)\n",
        "print(len(testName))\n",
        "\n",
        "brandMapTest = dict(zip(Name, [t for t in range(len(Name))]))\n",
        "print(brandMapTest)\n",
        "rBrandMapTest = dict(zip([t for t in range(len(Name))],Name))"
      ],
      "metadata": {
        "id": "la_N-L353Wwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "Brand = '/content/gdrive/MyDrive/DL Assignment/Part 3/logos3/train/Starbucks'\n",
        "import os\n",
        "subClass = os.listdir(Brand)\n",
        "\n",
        "fig = plt.figure(figsize = (10,5))\n",
        "for e in range(len(subClass[:10])):\n",
        "  plt.subplot(2,5,e+1)\n",
        "  img = plt.imread(os.path.join(Brand, subClass[e]))\n",
        "  plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "xkPpK7feX9y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image dimensions and batch size\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "hGd3w1gbmH6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Train data loaded from Train Directory. Create Train and Validation Data from the Training Data loaded. Validation data is 20% of Train data."
      ],
      "metadata": {
        "id": "vm_bA7nvm5oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators with data augmentation for training data\n",
        "trainDataGen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "byeLGSKfmN3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators for validation data\n",
        "validDataGen = ImageDataGenerator(rescale=1.0 / 255.0, validation_split=0.2)"
      ],
      "metadata": {
        "id": "00RLUDXXmbUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data from the images in the train directory\n",
        "trainGenerator = trainDataGen.flow_from_directory(\n",
        "    baseDir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "id": "AFDEa5cWmmUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate validation data from the images in the train directory\n",
        "validGenerator = validDataGen.flow_from_directory(\n",
        "    baseDir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "ou00aL-NmwIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Test data from the images loaded from the Test directory"
      ],
      "metadata": {
        "id": "aE6hmLU8nWm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate test data from the images in the test directory\n",
        "testDataGen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "testGenerator = testDataGen.flow_from_directory(\n",
        "    testDir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "ccWuc3KOnMVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Base Model for VGG-16"
      ],
      "metadata": {
        "id": "hCkUgo_dnqUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG-16 model\n",
        "baseModelVGG16 = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(img_height, img_width, 3)\n",
        ")\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in baseModelVGG16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "kVjhLILLnpJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a new model on top of the pre-trained model\n",
        "model = Sequential([\n",
        "    baseModelVGG16,\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "    Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(trainGenerator.num_classes, activation='softmax')  # Number of classes determined by the training generator\n",
        "])"
      ],
      "metadata": {
        "id": "z46IZn-An-e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KzpYLnYioMOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "y6AJ7vwXojkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the last fully connected layer\n",
        "numClasses = len(trainGenerator.class_indices)\n",
        "\n",
        "# Create a new fully connected layer with the appropriate number of output nodes\n",
        "newFCLayer = Dense(numClasses, activation='softmax')\n",
        "\n",
        "# Replace the last layer of the pre-trained model with the new fully connected layer\n",
        "model.layers[-1] = newFCLayer"
      ],
      "metadata": {
        "id": "XxbOtN0Mv0zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in baseModelVGG16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model again after modifying it\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SCPSmGgjv20x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train only the new fully connected layer using the training set\n",
        "epochsFineTune = 10  # Adjust the number of epochs for fine-tuning\n",
        "historyFineTune = model.fit(\n",
        "    trainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    validation_data=validGenerator,\n",
        "    validation_steps=validGenerator.samples // batch_size,\n",
        "    epochs=epochsFineTune\n",
        ")"
      ],
      "metadata": {
        "id": "lxUdXmtvwaoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the model using the validation set before fine-tuning\n",
        "valLossFineTune, valAccuracyFineTune = model.evaluate(validGenerator)\n",
        "print(\"Validation Loss before Fine-Tuning:\", valLossFineTune)\n",
        "print(\"Validation Accuracy before Fine-Tuning:\", valAccuracyFineTune)"
      ],
      "metadata": {
        "id": "_YXgpW5Rws3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(historyFineTune.history['accuracy'])\n",
        "plt.plot(historyFineTune.history['val_accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "training_accuracy = historyFineTune.history['loss']\n",
        "validation_accuracy = historyFineTune.history['val_loss']\n",
        "plt.plot(training_accuracy, 'r', label = 'training loss')\n",
        "plt.plot(validation_accuracy, 'b', label = 'validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f8GVszhfjwhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "testLoss, testAccuracy = model.evaluate(testGenerator)\n",
        "print(\"Test Loss:\", testLoss)\n",
        "print(\"Test Accuracy:\", testAccuracy)"
      ],
      "metadata": {
        "id": "XvJ1bbt5rSq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some of the pre-trained layers for further fine-tuning\n",
        "# For example, you can unfreeze the last few convolutional layers:\n",
        "for layer in baseModelVGG16.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model after unfreezing some layers\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TWs1uE-Kw6Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the model using the validation set after further fine-tuning\n",
        "epochsFinalFineTune = 10  # Adjust the number of epochs for final fine-tuning\n",
        "historyFinalFineTune = model.fit(\n",
        "    trainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    validation_data=validGenerator,\n",
        "    validation_steps=validGenerator.samples // batch_size,\n",
        "    epochs=epochsFinalFineTune\n",
        ")"
      ],
      "metadata": {
        "id": "gkBEvJ46xIsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the final fine-tuned model on the validation set after fine tunning the model\n",
        "valLossFinalFineTune, valAccuracyFinalFineTune = model.evaluate(validGenerator)\n",
        "print(\"Validation Loss after Final Fine-Tuning:\", valLossFinalFineTune)\n",
        "print(\"Validation Accuracy after Final Fine-Tuning:\", valAccuracyFinalFineTune)"
      ],
      "metadata": {
        "id": "s9LuKv14xWvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(historyFineTune.history['accuracy'])\n",
        "plt.plot(historyFineTune.history['val_accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation accuracy after fine tunning')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "training_accuracy = historyFineTune.history['loss']\n",
        "validation_accuracy = historyFineTune.history['val_loss']\n",
        "plt.plot(training_accuracy, 'r', label = 'training loss')\n",
        "plt.plot(validation_accuracy, 'b', label = 'validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wvq1UcaRlC20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data after fine tunning the model\n",
        "testLoss, testAccuracy = model.evaluate(testGenerator)\n",
        "print(\"Test Loss:\", testLoss)\n",
        "print(\"Test Accuracy:\", testAccuracy)"
      ],
      "metadata": {
        "id": "nq5jYxFFtHkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the names of all layers in the model\n",
        "for layer in model.layers:\n",
        "    print(layer.name)"
      ],
      "metadata": {
        "id": "hStHfIWdCFC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Choose a layer from which you want to visualize the feature maps\n",
        "layerName = 'conv2d_1'\n",
        "\n",
        "# Create a sub-model to extract feature maps from the chosen layer\n",
        "visualizationModel = Model(inputs=model.input, outputs=model.get_layer(layerName).output)\n",
        "\n",
        "# Choose an example image for visualization (use any image from your dataset)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from google.colab import files\n",
        "uploadedFiles = files.upload()\n",
        "\n",
        "exampleImageData = uploadedFiles['BKImage3.jpg']\n",
        "\n",
        "# Convert the image data to a BytesIO object\n",
        "exampleImageBytes = BytesIO(exampleImageData)\n",
        "\n",
        "exampleImage = image.load_img(exampleImageBytes, target_size=(224, 224))\n",
        "exampleImage = image.img_to_array(exampleImage)\n",
        "exampleImage = np.expand_dims(exampleImage, axis=0)\n",
        "exampleImage = preprocess_input(exampleImage)\n",
        "\n",
        "# Get the feature maps for the example image\n",
        "featureMaps = visualizationModel.predict(exampleImage)\n",
        "\n",
        "# Number of feature maps in the chosen layer\n",
        "numFeatureMaps = featureMaps.shape[-1]\n",
        "\n",
        "# Define the grid dimensions for plotting\n",
        "gridSize = int(np.ceil(np.sqrt(numFeatureMaps)))\n",
        "\n",
        "# Create a figure and axis for plotting\n",
        "fig, ax = plt.subplots(gridSize, gridSize, figsize=(10, 10))\n",
        "\n",
        "# Plot each feature map\n",
        "for i in range(numFeatureMaps):\n",
        "    row = i // gridSize\n",
        "    col = i % gridSize\n",
        "    ax[row, col].imshow(featureMaps[0, :, :, i], cmap='viridis')\n",
        "    ax[row, col].axis('off')\n",
        "\n",
        "# Display the uploaded image name as a title\n",
        "plt.suptitle('Uploaded Image: BKImage3.jpg', fontsize=16)\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-53btMz-K4gO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}